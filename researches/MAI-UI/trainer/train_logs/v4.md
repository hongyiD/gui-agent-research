amloth@fcf2aae2e869:/workspace/mai-ui-trainer/trainer$ python sft_trainer.py --config configs/my_config_119.y
Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu128 for torchao version 0.13.0
============================================================
Training Configuration Summary
============================================================
Model path: /workspace/MAI-UI-2B
Data path: /workspace/mai-ui-trainer/dataset/20260119_201327/sft_train.jsonl
Output directory: /workspace/mai-ui-trainer/trainer/models/sft_model/20260127_165045
Max length: 6200
Use LoRA: True
  LoRA r: 16
  LoRA alpha: 32
  LoRA dropout: 0.05
  LoRA target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj']
Use 4-bit quantization: True
Gradient checkpointing: True
============================================================

Using 4-bit quantization with compute dtype: torch.float16
GPU compute capability (7, 0), using float16 (V100 or older)
Loaded as Qwen3VL model with multi-modal support
VL Model: True
Gradient checkpointing enabled
All model parameters frozen for LoRA training
trainable params: 6,422,528 || all params: 2,133,954,560 || trainable%: 0.3010
LoRA applied successfully
Loading dataset from: /workspace/mai-ui-trainer/dataset/20260119_201327/sft_train.jsonl
Dataset size: 26
Sample keys: ['messages', 'metadata']
  messages: list with 3 items
    First item type: <class 'dict'>
  metadata: <class 'dict'>

Data contains images: True
Training with fp16=True (GPU does not support bfloat16, using float16)
Using MultiModalDataCollator for vision-language training (max 1 images/sample)
Image base directory: /workspace/mai-ui-trainer/dataset/20260119_201327

============================================================
DATASET PREPROCESSING
============================================================
  Max images per sample: 1
  Total samples: 26
  Data directory: /workspace/mai-ui-trainer/dataset/20260119_201327
Decoding images: 100%|███████████████████████████████████████████████████████| 26/26 [00:00<00:00, 64.67it/s]

============================================================
PREPROCESSING SUMMARY
============================================================
  Samples processed: 26
  Original images: 26 (1.0 avg/sample)
  After limiting: 26 (1.0 avg/sample)
  Avg image size: 460x1024 pixels
============================================================

Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.

NOTE: First step may be slow due to JIT compilation and image processing.
      Watch for detailed step-by-step logs below.

The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.

======================================================================
TRAINING STARTED
======================================================================
  Total steps: 35
  Epochs: 5
  Batch size: 1
  Gradient accumulation: 4
  Effective batch size: 4
  Learning rate: 0.0001
  FP16: True, BF16: False
  Gradient checkpointing: True
  GPU: Tesla V100-SXM2-32GB
  GPU Memory: 31.7 GB total
======================================================================

  0%|                                                                                 | 0/35 [00:00<?, ?it/s]
--- Epoch 1/5 ---
[DEBUG] apply_chat_template: 0.05s, processor: 0.04s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 1/35] time: 121.45s | VRAM: 2.2/31.7GB (7%) | ETA: 1.1h
{'loss': 0.8588, 'grad_norm': 7.341689586639404, 'learning_rate': 0.0, 'epoch': 0.15}                                   
  3%|██▎                                                                              | 1/35 [02:01<1:08:56, 121.67s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 2/35] time: 120.32s | loss: 0.8588 | lr: 0.00e+00 | VRAM: 2.2/31.7GB (7%) | ETA: 1.1h
{'loss': 0.4757, 'grad_norm': 2.230477809906006, 'learning_rate': 0.0001, 'epoch': 0.31}                                
  6%|████▋                                                                            | 2/35 [04:02<1:06:31, 120.96s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.04s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 3/35] time: 120.02s | loss: 0.4757 | lr: 1.00e-04 | VRAM: 2.2/31.7GB (7%) | ETA: 1.1h
{'loss': 0.5129, 'grad_norm': 1.607709288597107, 'learning_rate': 9.705882352941177e-05, 'epoch': 0.46}                 
  9%|██████▉                                                                          | 3/35 [06:02<1:04:19, 120.60s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 4/35] time: 125.04s | loss: 0.5129 | lr: 9.71e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 1.0h
{'loss': 0.5465, 'grad_norm': 2.1215333938598633, 'learning_rate': 9.411764705882353e-05, 'epoch': 0.62}                
 11%|█████████▎                                                                       | 4/35 [08:07<1:03:14, 122.41s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 5/35] time: 121.57s | loss: 0.5465 | lr: 9.41e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 1.0h
{'loss': 0.4338, 'grad_norm': 1.5557267665863037, 'learning_rate': 9.11764705882353e-05, 'epoch': 0.77}                 
 14%|███████████▌                                                                     | 5/35 [10:09<1:01:04, 122.16s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 6/35] time: 126.12s | loss: 0.4338 | lr: 9.12e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 59.3m
{'loss': 0.5218, 'grad_norm': 1.152769684791565, 'learning_rate': 8.823529411764706e-05, 'epoch': 0.92}                 
 17%|██████████████▏                                                                    | 6/35 [12:16<59:51, 123.83s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 7/35] time: 62.39s | loss: 0.5218 | lr: 8.82e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 53.2m
{'loss': 0.5185, 'grad_norm': 1.4670538902282715, 'learning_rate': 8.529411764705883e-05, 'epoch': 1.0}                 
 20%|████████████████▌                                                                  | 7/35 [13:18<48:25, 103.76s/it]
--- Epoch 2/5 ---
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 8/35] time: 122.28s | loss: 0.5185 | lr: 8.53e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 51.8m
{'loss': 0.4291, 'grad_norm': 1.0714162588119507, 'learning_rate': 8.23529411764706e-05, 'epoch': 1.15}                 
 23%|██████████████████▉                                                                | 8/35 [15:21<49:22, 109.71s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 9/35] time: 125.62s | loss: 0.4291 | lr: 8.24e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 50.4m
{'loss': 0.3415, 'grad_norm': 1.0322914123535156, 'learning_rate': 7.941176470588235e-05, 'epoch': 1.31}                
 26%|█████████████████████▎                                                             | 9/35 [17:26<49:42, 114.72s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 10/35] time: 124.92s | loss: 0.3415 | lr: 7.94e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 48.8m
{'loss': 0.4029, 'grad_norm': 0.8875566124916077, 'learning_rate': 7.647058823529411e-05, 'epoch': 1.46}                
 29%|███████████████████████▍                                                          | 10/35 [19:31<49:07, 117.91s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 11/35] time: 126.05s | loss: 0.4029 | lr: 7.65e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 47.2m
{'loss': 0.484, 'grad_norm': 0.9287259578704834, 'learning_rate': 7.352941176470589e-05, 'epoch': 1.62}                 
 31%|█████████████████████████▊                                                        | 11/35 [21:38<48:16, 120.68s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 12/35] time: 122.13s | loss: 0.4840 | lr: 7.35e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 45.4m
{'loss': 0.4116, 'grad_norm': 1.0798581838607788, 'learning_rate': 7.058823529411765e-05, 'epoch': 1.77}                
 34%|████████████████████████████                                                      | 12/35 [23:41<46:26, 121.16s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 13/35] time: 124.04s | loss: 0.4116 | lr: 7.06e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 43.6m
{'loss': 0.2768, 'grad_norm': 0.6254526376724243, 'learning_rate': 6.764705882352942e-05, 'epoch': 1.92}                
 37%|██████████████████████████████▍                                                   | 13/35 [25:45<44:45, 122.07s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 14/35] time: 60.10s | loss: 0.2768 | lr: 6.76e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 40.1m
{'loss': 0.3559, 'grad_norm': 1.4766616821289062, 'learning_rate': 6.470588235294118e-05, 'epoch': 2.0}                 
 40%|████████████████████████████████▊                                                 | 14/35 [26:45<36:10, 103.37s/it]
--- Epoch 3/5 ---
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 15/35] time: 118.57s | loss: 0.3559 | lr: 6.47e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 38.3m
{'loss': 0.3545, 'grad_norm': 0.7519465684890747, 'learning_rate': 6.176470588235295e-05, 'epoch': 2.15}                
 43%|███████████████████████████████████▏                                              | 15/35 [28:44<35:59, 108.00s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 16/35] time: 127.96s | loss: 0.3545 | lr: 6.18e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 36.7m
{'loss': 0.271, 'grad_norm': 0.7596238255500793, 'learning_rate': 5.882352941176471e-05, 'epoch': 2.31}                 
 46%|█████████████████████████████████████▍                                            | 16/35 [30:53<36:12, 114.32s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 17/35] time: 127.91s | loss: 0.2710 | lr: 5.88e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 35.0m
{'loss': 0.2527, 'grad_norm': 0.7697162628173828, 'learning_rate': 5.588235294117647e-05, 'epoch': 2.46}                
 49%|███████████████████████████████████████▊                                          | 17/35 [33:01<35:32, 118.45s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 18/35] time: 127.35s | loss: 0.2527 | lr: 5.59e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 33.2m
{'loss': 0.3911, 'grad_norm': 0.781610369682312, 'learning_rate': 5.294117647058824e-05, 'epoch': 2.62}                 
 51%|██████████████████████████████████████████▏                                       | 18/35 [35:08<34:19, 121.17s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 19/35] time: 126.74s | loss: 0.3911 | lr: 5.29e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 31.4m
{'loss': 0.3537, 'grad_norm': 0.8598079085350037, 'learning_rate': 5e-05, 'epoch': 2.77}                                
 54%|████████████████████████████████████████████▌                                     | 19/35 [37:15<32:46, 122.88s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 20/35] time: 120.71s | loss: 0.3537 | lr: 5.00e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 29.5m
{'loss': 0.3295, 'grad_norm': 0.8265032172203064, 'learning_rate': 4.705882352941177e-05, 'epoch': 2.92}                
 57%|██████████████████████████████████████████████▊                                   | 20/35 [39:16<30:34, 122.27s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 21/35] time: 60.28s | loss: 0.3295 | lr: 4.71e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 26.9m
{'loss': 0.4006, 'grad_norm': 1.3033243417739868, 'learning_rate': 4.411764705882353e-05, 'epoch': 3.0}                 
 60%|█████████████████████████████████████████████████▏                                | 21/35 [40:17<24:15, 103.95s/it]
--- Epoch 4/5 ---
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 22/35] time: 126.97s | loss: 0.4006 | lr: 4.41e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 25.1m
{'loss': 0.3549, 'grad_norm': 0.8479684591293335, 'learning_rate': 4.11764705882353e-05, 'epoch': 3.15}                 
 63%|███████████████████████████████████████████████████▌                              | 22/35 [42:24<24:01, 110.91s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 23/35] time: 124.74s | loss: 0.3549 | lr: 4.12e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 23.2m
{'loss': 0.2507, 'grad_norm': 0.7792523503303528, 'learning_rate': 3.8235294117647055e-05, 'epoch': 3.31}               
 66%|█████████████████████████████████████████████████████▉                            | 23/35 [44:29<23:01, 115.10s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 24/35] time: 132.34s | loss: 0.2507 | lr: 3.82e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 21.4m
{'loss': 0.2488, 'grad_norm': 0.6969645619392395, 'learning_rate': 3.529411764705883e-05, 'epoch': 3.46}                
 69%|████████████████████████████████████████████████████████▏                         | 24/35 [46:42<22:03, 120.31s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 25/35] time: 126.96s | loss: 0.2488 | lr: 3.53e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 19.5m
{'loss': 0.3544, 'grad_norm': 0.9215348958969116, 'learning_rate': 3.235294117647059e-05, 'epoch': 3.62}                
 71%|██████████████████████████████████████████████████████████▌                       | 25/35 [48:49<20:23, 122.35s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 26/35] time: 133.89s | loss: 0.3544 | lr: 3.24e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 17.7m
{'loss': 0.2917, 'grad_norm': 0.7030394077301025, 'learning_rate': 2.9411764705882354e-05, 'epoch': 3.77}               
 74%|████████████████████████████████████████████████████████████▉                     | 26/35 [51:04<18:54, 126.10s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 27/35] time: 129.76s | loss: 0.2917 | lr: 2.94e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 15.8m
{'loss': 0.2666, 'grad_norm': 0.8411824107170105, 'learning_rate': 2.647058823529412e-05, 'epoch': 3.92}                
 77%|███████████████████████████████████████████████████████████████▎                  | 27/35 [53:14<16:57, 127.24s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 28/35] time: 65.98s | loss: 0.2666 | lr: 2.65e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 13.6m
{'loss': 0.3237, 'grad_norm': 1.0720494985580444, 'learning_rate': 2.3529411764705884e-05, 'epoch': 4.0}                
 80%|█████████████████████████████████████████████████████████████████▌                | 28/35 [54:20<12:42, 108.87s/it]
--- Epoch 5/5 ---
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.04s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 29/35] time: 123.48s | loss: 0.3237 | lr: 2.35e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 11.7m
{'loss': 0.2962, 'grad_norm': 0.8623480796813965, 'learning_rate': 2.058823529411765e-05, 'epoch': 4.15}                
 83%|███████████████████████████████████████████████████████████████████▉              | 29/35 [56:23<11:19, 113.31s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 30/35] time: 126.68s | loss: 0.2962 | lr: 2.06e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 9.8m
{'loss': 0.1769, 'grad_norm': 0.6947875022888184, 'learning_rate': 1.7647058823529414e-05, 'epoch': 4.31}               
 86%|██████████████████████████████████████████████████████████████████████▎           | 30/35 [58:30<09:46, 117.36s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 31/35] time: 125.43s | loss: 0.1769 | lr: 1.76e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 7.8m
{'loss': 0.2688, 'grad_norm': 0.7826847434043884, 'learning_rate': 1.4705882352941177e-05, 'epoch': 4.46}               
 89%|██████████████████████████████████████████████████████████████████████▊         | 31/35 [1:00:37<08:00, 120.09s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[Step 32/35] time: 121.39s | loss: 0.2688 | lr: 1.47e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 5.9m
{'loss': 0.3156, 'grad_norm': 0.6925332546234131, 'learning_rate': 1.1764705882352942e-05, 'epoch': 4.62}               
 91%|█████████████████████████████████████████████████████████████████████████▏      | 32/35 [1:02:38<06:01, 120.52s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 33/35] time: 118.90s | loss: 0.3156 | lr: 1.18e-05 | VRAM: 2.2/31.7GB (7%) | ETA: 3.9m
{'loss': 0.2734, 'grad_norm': 0.8883585333824158, 'learning_rate': 8.823529411764707e-06, 'epoch': 4.77}                
 94%|███████████████████████████████████████████████████████████████████████████▍    | 33/35 [1:04:37<04:00, 120.07s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.02s
[DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 34/35] time: 119.55s | loss: 0.2734 | lr: 8.82e-06 | VRAM: 2.2/31.7GB (7%) | ETA: 2.0m
{'loss': 0.3065, 'grad_norm': 0.9132334589958191, 'learning_rate': 5.882352941176471e-06, 'epoch': 4.92}                
 97%|█████████████████████████████████████████████████████████████████████████████▋  | 34/35 [1:06:37<01:59, 119.96s/it][DEBUG] apply_chat_template: 0.00s, processor: 0.03s
[Step 35/35] time: 63.29s | loss: 0.3065 | lr: 5.88e-06 | VRAM: 2.2/31.7GB (7%) | ETA: 0s
{'loss': 0.2805, 'grad_norm': 1.3838310241699219, 'learning_rate': 2.9411764705882355e-06, 'epoch': 5.0}                
{'train_runtime': 4061.5205, 'train_samples_per_second': 0.032, 'train_steps_per_second': 0.009, 'train_loss': 0.3694802705730711, 'epoch': 5.0}
100%|████████████████████████████████████████████████████████████████████████████████| 35/35 [1:07:41<00:00, 102.97s/it]
======================================================================
TRAINING COMPLETED
======================================================================
  Total time: 1.1h
  Total steps: 35
  Final loss: 0.2805
  Peak GPU memory: 8.35 GB
======================================================================

100%|████████████████████████████████████████████████████████████████████████████████| 35/35 [1:07:41<00:00, 116.04s/it]
LoRA weights saved to /workspace/mai-ui-trainer/trainer/models/sft_model/20260127_165045
Processor saved to /workspace/mai-ui-trainer/trainer/models/sft_model/20260127_165045
SFT training completed. Output saved to /workspace/mai-ui-trainer/trainer/models/sft_model/20260127_165045