# MAI-UI è®­ç»ƒå¯åŠ¨æŒ‡å—

## ğŸ“‹ å¼€å§‹è®­ç»ƒå‰çš„æ£€æŸ¥æ¸…å•

### âœ… 1. ç¯å¢ƒå·²å®‰è£…
- [x] Python ç¯å¢ƒå·²å®‰è£…
- [x] ä¾èµ–å·²å®‰è£… (`pip install -r requirements.txt`)

### âœ… 2. å‡†å¤‡è®­ç»ƒæ•°æ®

ç¡®ä¿ä½ æœ‰åŸå§‹è½¨è¿¹æ•°æ®ï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š
```
your_data_root/
â”œâ”€â”€ task1/
â”‚   â”œâ”€â”€ traj.json          # è½¨è¿¹æ—¥å¿—ï¼ˆå¿…éœ€ï¼‰
â”‚   â”œâ”€â”€ screenshots/        # æˆªå›¾ç›®å½•ï¼ˆå¿…éœ€ï¼‰
â”‚   â””â”€â”€ result.txt         # è¯„åˆ†æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
â”œâ”€â”€ task2/
â”‚   â””â”€â”€ ...
```

**å¦‚æœæ²¡æœ‰æ•°æ®**ï¼Œä½ éœ€è¦å…ˆè¿è¡Œä¸Šæ¸¸çš„ agent ç”Ÿæˆè½¨è¿¹æ—¥å¿—ã€‚

### âœ… 3. é…ç½®è®­ç»ƒå‚æ•°

ç¼–è¾‘ `configs/my_config.yaml`ï¼Œ**å¿…é¡»ä¿®æ”¹**ä»¥ä¸‹å‚æ•°ï¼š

```yaml
# 1. æ•°æ®è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
data:
  raw_data_dir: "/path/to/your/trajectory/logs"  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®ç›®å½•

# 2. æ¨¡å‹è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
model:
  path: "Tongyi-MAI/MAI-UI-2B"  # å¦‚æœä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œæ”¹ä¸ºæœ¬åœ°è·¯å¾„

# 3. GPU è®¾ç½®ï¼ˆæ ¹æ®ä½ çš„ç¡¬ä»¶ï¼‰
resources:
  gpu_ids: [0]  # ä¿®æ”¹ä¸ºä½ çš„ GPU IDï¼Œå¦‚ [0, 1] è¡¨ç¤ºä½¿ç”¨ GPU 0 å’Œ 1
```

**å¯é€‰é…ç½®**ï¼š
- `training.sft.num_train_epochs`: è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤ 3ï¼‰
- `training.sft.per_device_train_batch_size`: æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ 2ï¼Œæ ¹æ®æ˜¾å­˜è°ƒæ•´ï¼‰
- `training.sft.learning_rate`: å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 2e-5ï¼‰

---

## ğŸš€ å¼€å§‹è®­ç»ƒ

### æ–¹å¼ 1ï¼šä¸€é”®å¯åŠ¨ï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
cd trainer
bash scripts/quick_start.sh --config configs/my_config.yaml
```

è¿™ä¼šè‡ªåŠ¨å®Œæˆï¼š
- âœ… æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯
- âœ… SFT è®­ç»ƒ
- âœ… æ¨¡å‹è¯„ä¼°

### æ–¹å¼ 2ï¼šåˆ†æ­¥æ‰§è¡Œï¼ˆæ¨èæœ‰ç»éªŒçš„ç”¨æˆ·ï¼‰

#### æ­¥éª¤ 1ï¼šæ•°æ®é¢„å¤„ç†

```bash
python data/unified_data_processor.py \
    --config configs/my_config.yaml \
    --output_format prompt_response \
    --validate
```

**æ£€æŸ¥è¾“å‡º**ï¼š
- å¤„ç†åçš„æ•°æ®ï¼š`../../dataset/processed/sft_train.jsonl`
- éªŒè¯æŠ¥å‘Šï¼šæ£€æŸ¥ç»ˆç«¯è¾“å‡ºçš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯

#### æ­¥éª¤ 2ï¼šSFT è®­ç»ƒ

```bash
python sft_trainer.py --config configs/my_config.yaml
```

**è®­ç»ƒè¿‡ç¨‹**ï¼š
- æ¨¡å‹ä¼šä¿å­˜åˆ°ï¼š`./models/sft_model/`
- Checkpoint æ¯ 100 æ­¥ä¿å­˜ä¸€æ¬¡ï¼ˆå¯åœ¨é…ç½®ä¸­ä¿®æ”¹ï¼‰
- è®­ç»ƒæ—¥å¿—ä¼šæ˜¾ç¤º lossã€å­¦ä¹ ç‡ç­‰ä¿¡æ¯

**ç›‘æ§è®­ç»ƒ**ï¼š
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f pipeline_logs/training.log

# å¦‚æœå¯ç”¨äº† TensorBoard
tensorboard --logdir tensorboard_logs
```

#### æ­¥éª¤ 3ï¼šæ¨¡å‹è¯„ä¼°ï¼ˆå¯é€‰ï¼‰

```bash
python evaluate.py \
    --agent_type mai_ui_agent \
    --model_name ./models/sft_model \
    --llm_base_url https://api.openai.com/v1 \
    --log_root ./eval_logs \
    --max_step 50
```

**æ³¨æ„**ï¼šè¯„ä¼°éœ€è¦ LLM APIï¼Œè®¾ç½® `--llm_base_url` æˆ–ç¯å¢ƒå˜é‡ `LLM_BASE_URL`

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ•°æ®è·¯å¾„é”™è¯¯
**é”™è¯¯**ï¼š`FileNotFoundError: No such file or directory`

**è§£å†³**ï¼š
1. æ£€æŸ¥ `data.raw_data_dir` è·¯å¾„æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äº `trainer/` ç›®å½•çš„ç›¸å¯¹è·¯å¾„
3. éªŒè¯æ•°æ®ç›®å½•ä¸‹æ˜¯å¦æœ‰ `traj.json` æ–‡ä»¶

### Q2: æ˜¾å­˜ä¸è¶³ (OOM)
**é”™è¯¯**ï¼š`RuntimeError: CUDA out of memory`

**è§£å†³**ï¼š
1. å‡å° `per_device_train_batch_size`ï¼ˆå¦‚ä» 2 æ”¹ä¸º 1ï¼‰
2. å¢åŠ  `gradient_accumulation_steps`ï¼ˆå¦‚ä» 8 æ”¹ä¸º 16ï¼‰
3. å‡å° `max_length`ï¼ˆå¦‚ä» 2048 æ”¹ä¸º 1024ï¼‰
4. ä½¿ç”¨ `bf16: false` å…³é—­æ··åˆç²¾åº¦ï¼ˆå¦‚æœæ”¯æŒï¼‰

### Q3: è®­ç»ƒä¸­æ–­åå¦‚ä½•æ¢å¤ï¼Ÿ
```bash
# è‡ªåŠ¨æ£€æµ‹æœ€æ–° checkpoint å¹¶æ¢å¤
python scripts/resume_training.py \
    --model_dir ./models/sft_model \
    --config configs/my_config.yaml
```

### Q4: å¦‚ä½•åªè®­ç»ƒä¸è¯„ä¼°ï¼Ÿ
ç¼–è¾‘ `configs/my_config.yaml`ï¼š
```yaml
pipeline:
  stages:
    data_preprocessing: true
    data_validation: true
    sft_training: true
    sft_evaluation: false  # å…³é—­è¯„ä¼°
    rl_training: false
    final_evaluation: false
```

---

## ğŸ“Š è®­ç»ƒè¾“å‡ºè¯´æ˜

### æ¨¡å‹æ–‡ä»¶ç»“æ„
```
models/sft_model/
â”œâ”€â”€ checkpoint-100/      # ç¬¬ 100 æ­¥çš„ checkpoint
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ tokenizer files
â”œâ”€â”€ checkpoint-200/      # ç¬¬ 200 æ­¥çš„ checkpoint
â””â”€â”€ ...
```

### æ—¥å¿—æ–‡ä»¶
```
pipeline_logs/
â”œâ”€â”€ training.log         # è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ data_processing.log  # æ•°æ®å¤„ç†æ—¥å¿—
â””â”€â”€ evaluation.log       # è¯„ä¼°æ—¥å¿—
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼š
1. **æŸ¥çœ‹è¯„ä¼°ç»“æœ**ï¼šæ£€æŸ¥ `eval_logs/` ç›®å½•ä¸‹çš„ç»“æœ
2. **æ‰¹é‡è¯„ä¼°**ï¼šä½¿ç”¨ `evaluation/batch_evaluator.py` è¯„ä¼°æ‰€æœ‰ checkpoint
3. **RL è®­ç»ƒ**ï¼ˆå¯é€‰ï¼‰ï¼šå¦‚æœ SFT æ•ˆæœæ»¡æ„ï¼Œå¯ä»¥å¼€å¯ RL è®­ç»ƒ

---

## ğŸ“š æ›´å¤šèµ„æº

- **è¯¦ç»†æ–‡æ¡£**ï¼š`docs/DATA_FORMAT.md` - æ•°æ®æ ¼å¼è¯´æ˜
- **æ•…éšœæ’æŸ¥**ï¼š`docs/TROUBLESHOOTING.md` - å¸¸è§é—®é¢˜
- **é…ç½®è¯´æ˜**ï¼š`README.md` - å®Œæ•´é…ç½®å‚æ•°è¯´æ˜

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ‰
